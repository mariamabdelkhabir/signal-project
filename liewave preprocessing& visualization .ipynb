{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7837771,"sourceType":"datasetVersion","datasetId":4594422},{"sourceId":7837776,"sourceType":"datasetVersion","datasetId":4594425},{"sourceId":7948344,"sourceType":"datasetVersion","datasetId":4674009}],"dockerImageVersionId":30664,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-26T18:39:25.024427Z","iopub.execute_input":"2024-03-26T18:39:25.024801Z","iopub.status.idle":"2024-03-26T18:39:25.052302Z","shell.execute_reply.started":"2024-03-26T18:39:25.024772Z","shell.execute_reply":"2024-03-26T18:39:25.051150Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import display\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np\nimport os\nimport shutil\nimport posixpath\n\nimport wfdb\n\nfrom scipy.signal import butter, filtfilt\nimport matplotlib.pyplot as plt\n","metadata":{"execution":{"iopub.status.busy":"2024-03-26T18:39:30.511663Z","iopub.execute_input":"2024-03-26T18:39:30.512062Z","iopub.status.idle":"2024-03-26T18:39:30.519743Z","shell.execute_reply.started":"2024-03-26T18:39:30.512031Z","shell.execute_reply":"2024-03-26T18:39:30.518854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"S1_S1=pd.read_csv('/kaggle/input/raw-data-liewaves/S10S1.csv')\nS1_S1","metadata":{"execution":{"iopub.status.busy":"2024-03-26T18:39:32.729394Z","iopub.execute_input":"2024-03-26T18:39:32.729796Z","iopub.status.idle":"2024-03-26T18:39:32.777322Z","shell.execute_reply.started":"2024-03-26T18:39:32.729764Z","shell.execute_reply":"2024-03-26T18:39:32.776518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"S1_S2=pd.read_csv('/kaggle/input/raw-data-liewaves/S10S2.csv')\nS1_S2","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:50:31.675526Z","iopub.execute_input":"2024-03-26T14:50:31.676600Z","iopub.status.idle":"2024-03-26T14:50:31.718875Z","shell.execute_reply.started":"2024-03-26T14:50:31.676545Z","shell.execute_reply":"2024-03-26T14:50:31.716904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(24,8))\n\n# Define the offset\noffset = 500  # adjust this value as needed\n\n# Plot each channel with an increasing offset\nchannels = ['EEG.AF3', 'EEG.T7', 'EEG.Pz','EEG.T8','EEG.AF4']  # replace with your actual channel names\nfor i, channel in enumerate(channels):\n    plt.plot(S1_S1[channel] + i * offset, label=channel)\n\nplt.legend(loc='upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:52:35.335213Z","iopub.execute_input":"2024-03-26T14:52:35.336484Z","iopub.status.idle":"2024-03-26T14:52:35.773132Z","shell.execute_reply.started":"2024-03-26T14:52:35.336434Z","shell.execute_reply":"2024-03-26T14:52:35.771978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(24,8))\n\n# Define the offset\noffset = 500  # adjust this value as needed\n\n# Plot each channel with an increasing offset\nchannels = ['EEG.AF3', 'EEG.T7', 'EEG.Pz','EEG.T8','EEG.AF4']  # replace with your actual channel names\nfor i, channel in enumerate(channels):\n    plt.plot(S1_S2[channel] + i * offset, label=channel)\n\nplt.legend(loc='upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-26T14:52:31.216954Z","iopub.execute_input":"2024-03-26T14:52:31.217411Z","iopub.status.idle":"2024-03-26T14:52:31.648079Z","shell.execute_reply.started":"2024-03-26T14:52:31.217377Z","shell.execute_reply":"2024-03-26T14:52:31.646903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Load normal and abnormal EEG data from CSV files\nnormal_data = pd.read_csv('/kaggle/input/raw-data-liewaves/S10S1.csv')  # tell the truth\nabnormal_data = pd.read_csv('/kaggle/input/raw-data-liewaves/S10S2.csv') # lie\n\n# Add a label column to distinguish between normal (0) and abnormal (1) signals\nnormal_data['Label'] = 0\nabnormal_data['Label'] = 1\n\n# Concatenate normal and abnormal data\nmerged_data = pd.concat([normal_data, abnormal_data], ignore_index=True)\n\n# Shuffle the merged data\nshuffled_data = merged_data.sample(frac=1, random_state=42).reset_index(drop=True)\n\n# Convert shuffled_data to DataFrame explicitly\nshuffled_data_df = pd.DataFrame(shuffled_data)\n\n# Save the shuffled merged data to a new CSV file\nshuffled_data_df.to_csv('merged_signals.csv', index=False)\n\n# Display the first few rows of the shuffled merged data\nprint(shuffled_data_df.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T17:31:00.776354Z","iopub.execute_input":"2024-03-27T17:31:00.776786Z","iopub.status.idle":"2024-03-27T17:31:00.987581Z","shell.execute_reply.started":"2024-03-27T17:31:00.776756Z","shell.execute_reply":"2024-03-27T17:31:00.986013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shuffled_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# splitting the data","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Generate synthetic EEG data for demonstration\n# Assume 3 channels and 1000 data points per channel\nnum_channels = 6\nnum_data_points = 19200\nshuffled_data = np.random.randn(num_channels, num_data_points)\n\n# Split data into training and test sets\nsplit_ratio = 0.7  # 70% for training, 30% for testing\n\n# Calculate the number of samples for training and test sets\nnum_train_samples = int(num_data_points * split_ratio)\nnum_test_samples = num_data_points - num_train_samples\n\n# Split data\ntrain_data = shuffled_data[:, :num_train_samples]\ntest_data = shuffled_data[:, num_train_samples:]\n\n# Optionally, if you also want to split the filtered data, you can do it as follows:\n# train_filtered_data = filtered_data[:, :num_train_samples]\n# test_filtered_data = filtered_data[:, num_train_samples:]\n\n# Print the shapes of the training and test data sets\nprint(f\"Shape of train_data: {train_data.shape}\")\nprint(f\"Shape of test_data: {test_data.shape}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T17:32:29.710052Z","iopub.execute_input":"2024-03-27T17:32:29.710526Z","iopub.status.idle":"2024-03-27T17:32:29.721377Z","shell.execute_reply.started":"2024-03-27T17:32:29.710494Z","shell.execute_reply":"2024-03-27T17:32:29.719825Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom scipy.signal import butter, filtfilt\nimport matplotlib.pyplot as plt\n\ndef butter_bandpass(lowcut, highcut, fs, order=5):\n    nyquist_freq = 0.5 * fs\n    low = lowcut / nyquist_freq\n    high = highcut / nyquist_freq\n    b, a = butter(order, [low, high], btype='band')\n    return b, a\n\ndef butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n    y = filtfilt(b, a, data)\n    return y\n\n# Generate synthetic EEG data for demonstration\nnum_channels = 5\nnum_data_points = 19200\nfs = 128  # Sampling frequency in Hz\nt = np.linspace(0, 1, num_data_points, endpoint=False)\nshuffled_data = np.random.randn(num_channels, num_data_points)\n\n# Apply bandpass filter to each channel\nlowcut = 0.5  # Lower cutoff frequency in Hz\nhighcut = 45  # Higher cutoff frequency in Hz\nfiltered_data = np.zeros_like(shuffled_data)\n\nfor i in range(num_channels):\n    filtered_data[i, :] = butter_bandpass_filter(shuffled_data[i, :], lowcut, highcut, fs)\n\n# Plot original and filtered EEG signals for all channels in separate subplots\nfig, axs = plt.subplots(num_channels, 1, figsize=(12, 6*num_channels))\n\nfor i in range(num_channels):\n    axs[i].plot(t, shuffled_data[i, :], label=f'Original EEG (Channel {i+1})', alpha=0.7)\n    axs[i].plot(t, filtered_data[i, :], label=f'Filtered EEG (Channel {i+1})', alpha=0.7)\n    axs[i].set_title(f'Original and Filtered EEG Signals (Channel {i+1})')\n    axs[i].set_xlabel('Time (s)')\n    axs[i].set_ylabel('Amplitude')\n    axs[i].grid(True)\n    axs[i].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T17:34:45.988326Z","iopub.execute_input":"2024-03-27T17:34:45.988820Z","iopub.status.idle":"2024-03-27T17:34:50.785372Z","shell.execute_reply.started":"2024-03-27T17:34:45.988788Z","shell.execute_reply":"2024-03-27T17:34:50.783939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtered_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# converting filterd data to CSV file","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Load existing CSV file to get column names\nshuffled_data = pd.read_csv('merged_signals.csv')\n\n# Get column names from existing DataFrame\ncolumn_names = shuffled_data.columns.tolist()[:5]\n\n# Assuming filtered_data is a NumPy array with shape (19200, 5)\n# Transpose filtered_data to have 5 columns and 19200 rows\nfiltered_data_transposed = filtered_data.T\n\n# Convert transposed array to DataFrame with existing column names\ndf = pd.DataFrame(filtered_data_transposed, columns=column_names)\n\n# Save DataFrame to CSV file\ndf.to_csv('array_data.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T17:36:38.727945Z","iopub.execute_input":"2024-03-27T17:36:38.728361Z","iopub.status.idle":"2024-03-27T17:36:38.922380Z","shell.execute_reply.started":"2024-03-27T17:36:38.728331Z","shell.execute_reply":"2024-03-27T17:36:38.921206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:03:26.624088Z","iopub.execute_input":"2024-03-27T18:03:26.624574Z","iopub.status.idle":"2024-03-27T18:03:26.641750Z","shell.execute_reply.started":"2024-03-27T18:03:26.624531Z","shell.execute_reply":"2024-03-27T18:03:26.640613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# filtered data with bandpass","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Read the CSV file\ndf = pd.read_csv('array_data.csv')\n\n# Get column names (assuming each column represents a different channel)\nchannels = df.columns\n\n# Create a new figure\nplt.figure(figsize=(15, 10))\n\n# Plot each channel in a separate subplot\nfor i, channel in enumerate(channels):\n    plt.subplot(len(channels), 1, i+1)\n    plt.plot(cleaned_data[channel])\n    plt.title(f'Channel {channel}')\n    plt.xlabel('Time')\n    plt.ylabel('Amplitude')\n    plt.grid(True)\n\n# Adjust layout to prevent overlap\nplt.tight_layout()\n\n# Show the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T17:58:13.084485Z","iopub.execute_input":"2024-03-27T17:58:13.085038Z","iopub.status.idle":"2024-03-27T17:58:14.499516Z","shell.execute_reply.started":"2024-03-27T17:58:13.085002Z","shell.execute_reply":"2024-03-27T17:58:14.498327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# individual channels ATAR algorithm","metadata":{}},{"cell_type":"code","source":"import mne\nimport pandas as pd\n\n# Load EEG data from CSV\ndf = pd.read_csv('array_data.csv')\n\n# Iterate over each EEG channel for individual processing\nfor channel_name in df.columns[1:]:\n    # Create MNE Raw object from the channel data\n    info = mne.create_info(ch_names=[channel_name], sfreq=250, ch_types='eeg')\n    raw_channel = mne.io.RawArray(df[channel_name].values.reshape(1, -1), info)\n\n    # Apply preprocessing steps (e.g., filtering, artifact removal) to the channel data\n    # Example: Bandpass filter\n    raw_channel.filter(l_freq=0.5, h_freq=40)\n\n    # Save cleaned channel data back to the DataFrame\n    df[channel_name] = raw_channel.get_data()[0]\n\n# Save cleaned EEG data with individual channel processing to CSV\ndf.to_csv('cleaned_eeg_data.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T17:40:24.837559Z","iopub.execute_input":"2024-03-27T17:40:24.838035Z","iopub.status.idle":"2024-03-27T17:40:28.697015Z","shell.execute_reply.started":"2024-03-27T17:40:24.838001Z","shell.execute_reply":"2024-03-27T17:40:28.695805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Read the CSV file\ncleaned_data = pd.read_csv('cleaned_eeg_data.csv')\n\n# Display the first few rows of the DataFrame\nprint(cleaned_data.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T17:41:39.848450Z","iopub.execute_input":"2024-03-27T17:41:39.848870Z","iopub.status.idle":"2024-03-27T17:41:39.885129Z","shell.execute_reply.started":"2024-03-27T17:41:39.848838Z","shell.execute_reply":"2024-03-27T17:41:39.883861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Read the CSV file\ncleaned_data = pd.read_csv('cleaned_eeg_data.csv')\n\n# Get column names (assuming each column represents a different channel)\nchannels = cleaned_data.columns\n\n# Create a new figure\nplt.figure(figsize=(15, 10))\n\n# Plot each channel in a separate subplot\nfor i, channel in enumerate(channels):\n    plt.subplot(len(channels), 1, i+1)\n    plt.plot(cleaned_data[channel])\n    plt.title(f'Channel {channel}')\n    plt.xlabel('Time')\n    plt.ylabel('Amplitude')\n    plt.grid(True)\n\n# Adjust layout to prevent overlap\nplt.tight_layout()\n\n# Show the plot\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T17:43:16.539095Z","iopub.execute_input":"2024-03-27T17:43:16.539499Z","iopub.status.idle":"2024-03-27T17:43:17.948249Z","shell.execute_reply.started":"2024-03-27T17:43:16.539462Z","shell.execute_reply":"2024-03-27T17:43:17.946982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Read the first CSV file\ndf = pd.read_csv('array_data.csv')\n\n# Read the second CSV file for comparison\ncleaned_data = pd.read_csv('cleaned_eeg_data.csv')\n\n\n# Get column names (assuming each column represents a different channel)\nchannels = df.columns\n\n# Create a new figure\nplt.figure(figsize=(15, 10))\n\n# Plot each channel in a separate subplot\nfor i, channel in enumerate(channels):\n    plt.subplot(len(channels), 1, i+1)\n    plt.plot(df[channel], label=f'filtered data with bandpass (Channel {channel})', alpha=0.7)\n    plt.plot(cleaned_data[channel], label=f'cleaned data with ATAR (Channel {channel})', alpha=0.7)\n    plt.title(f'Channel {channel}')\n    plt.xlabel('Time')\n    plt.ylabel('Amplitude')\n    plt.grid(True)\n    plt.legend()\n\n# Adjust layout to prevent overlap\nplt.tight_layout()\n\n# Show the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:05:03.769862Z","iopub.execute_input":"2024-03-27T18:05:03.770329Z","iopub.status.idle":"2024-03-27T18:05:06.636690Z","shell.execute_reply.started":"2024-03-27T18:05:03.770298Z","shell.execute_reply":"2024-03-27T18:05:06.635452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# collective channels ATAR algorithm","metadata":{}},{"cell_type":"code","source":"import mne\nimport pandas as pd\n\n# Load EEG data from CSV\ndf = pd.read_csv('array_data.csv')\n\n# Create MNE Raw object from the DataFrame\ninfo = mne.create_info(ch_names=df.columns[1:], sfreq=250, ch_types='eeg')\nraw = mne.io.RawArray(df.values[:, 1:].T, info)\n\n# Perform collective channel processing (e.g., ICA)\nica = mne.preprocessing.ICA(n_components=20, random_state=42)\nica.fit(raw)\n\n# Plot ICA components to identify artifacts\nica.plot_components()\n\n# Choose components to exclude based on artifact patterns\nica.exclude = [0, 1, 2]  # Example: components to exclude\n\n# Apply artifact removal to all channels\ndf = raw.copy().apply_ica(ica)\n\n# Save cleaned EEG data to CSV\ncleaned_eeg_data2 = pd.DataFrame(df.get_data().T, columns=df.columns[1:])\ncleaned_eeg_data2.to_csv('cleaned_eeg_data2.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T18:20:49.828236Z","iopub.execute_input":"2024-03-27T18:20:49.828750Z","iopub.status.idle":"2024-03-27T18:20:49.935058Z","shell.execute_reply.started":"2024-03-27T18:20:49.828715Z","shell.execute_reply":"2024-03-27T18:20:49.932300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}